{"docstore/metadata": {"https://www.superannotate.com/blog/llm-fine-tuning": {"doc_hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2"}, "https://huggingface.co/docs/autotrain/en/llm_finetuning": {"doc_hash": "28b434e5790f667b01c65373aa0ef001751b67bfa1594ebf4c478fa22e0152f5"}, "dbcc8a39-c151-4294-8bbd-1250c20cd68b": {"doc_hash": "b380c1299cdaecb0e84b5df5532bc593cce223ccf0af35be28864447b1b89d50", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "54a2be4f-7ea2-4007-aee7-a4740bccbf5f": {"doc_hash": "6257c3d4d68efad192962a6b4f3b56f88a2dbc7c62908db93f21c9901cb3b7d1", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "4ee12d5a-0677-48d0-8e24-6e1bc8983123": {"doc_hash": "a45b091d186bc73bf9096772062c92aad5b41cd34fca3f505ec35cec5f55de9c", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "12aa42a6-916b-403e-8ede-a9fd74920948": {"doc_hash": "358667751501cd37f3df744f6e12f17f5fdff27ddb1225cebab117915f99f5e8", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "fba7d9d1-33e2-4c1d-8059-8bb627998ed7": {"doc_hash": "4374a44ba18df88c7c2925d54da949b0dd55dd002746782938833c91fcfb92e0", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "a13b8a84-de91-480d-84ba-bbd6cd9d1c46": {"doc_hash": "676c67fb45c5136ebe82e6cbc12e8b1bcf9878c499263dac3ede18daed59bbe7", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "6caa0c66-12bc-408d-808a-1b12e97af0c9": {"doc_hash": "72212e3e424187190d889e5152c3c0d5645bcc917d0d3154e3b68e298b6293c8", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "9bc76aa2-e6ba-4919-ab73-7faa2108603d": {"doc_hash": "62230a4f3a457d2733129b604bf76c8a4d508c7ed7242609f2efabf7aeb7c44f", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "cb2ff625-795d-4822-a50c-17d3716352ec": {"doc_hash": "89ed28039cd7339f34b828c8e1f9b1ef5fbb365ab88b0b79046436d20853c87a", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd": {"doc_hash": "670f28234af60d444bd88e41c1a467527b931baee4cdf9b3808f2997a2f082fa", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "acc57967-9b3e-4843-8a89-3b6aa77acff8": {"doc_hash": "d82966b3218729c09367a44e228761171f0844305025365734647685b9a4d2e4", "ref_doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "e5615b6f-9d90-43e2-ad2e-3ac7999418aa": {"doc_hash": "91fa209aabfae81d16e2c5019587e68bf34b1efc814c63d3df364a2bede8443f", "ref_doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "9367eb84-c69a-408b-ac65-eddbd8d4be9f": {"doc_hash": "bfc69a42800ddda69cefb14b4be2350403998582f2fec2f0ee8dfade6c024f34", "ref_doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "c73b40ca-c266-4888-a2fb-742ae2fcb791": {"doc_hash": "b100d8662f6cd3e17037733504b76d4e0d130e098f4252b10615659d77d9f46b", "ref_doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "1baf43b1-3ef9-445c-a405-8b9ad040700b": {"doc_hash": "190f6b0dc7de559a19c8ffb8a2b000cc88201f27db32e420219c47efd3f8711b", "ref_doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}}, "docstore/data": {"dbcc8a39-c151-4294-8bbd-1250c20cd68b": {"__data__": {"id_": "dbcc8a39-c151-4294-8bbd-1250c20cd68b", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54a2be4f-7ea2-4007-aee7-a4740bccbf5f", "node_type": "1", "metadata": {}, "hash": "b0dc958a4ed48fc9487594d70820f99bdb91437ca6b30e9652b748f02f190e40", "class_name": "RelatedNodeInfo"}}, "text": "Join our upcoming webinar \u00e2\u0080\u009cDeriving Business Value from LLMs and RAGs.\u00e2\u0080\u009d\n\n[Register\nnow](https://www.superannotate.com/webinar?utm_source=alert_bar&utm_medium=banner&utm_campaign=website_alert_bar)\n\n[![superannotate logo](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/6127731d30dc5270fa629b99_logoDark.svg)![](https://assets-\nglobal.website-\nfiles.com/612770618d97595db63a9470/612dea788938e85714b0d752_Logo_Footer.svg)](/)\n\nPlatform\n\n[\u00ee\u00a4\u009aFineTuneCreate top-quality training data across all data\ntypes.](/annotation-tool)\n\n[LLM![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/llms)[Image![](https://assets-\nglobal.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/image-\nannotation-tool)[Video![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/video-\nannotation)[Text![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/text-\nannotation)[Audio![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/audio-\nannotation)\n\n[\u00ee\u00a4\u0098ExploreManage, version, and debug your data and create more accurate\ndatasets faster.](/data-curation)[\u00ee\u00a4\u0099OrchestrateCreate CI/CD AI pipelines\nusing our built-in neural networks, Python SDK, webhooks, and advanced\norchestration.](/orchestrate)[\u00ee\u00a4\u0084WForceAccess a global marketplace of 400+\nvetted annotation service teams.", "start_char_idx": 0, "end_char_idx": 1566, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54a2be4f-7ea2-4007-aee7-a4740bccbf5f": {"__data__": {"id_": "54a2be4f-7ea2-4007-aee7-a4740bccbf5f", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dbcc8a39-c151-4294-8bbd-1250c20cd68b", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "b380c1299cdaecb0e84b5df5532bc593cce223ccf0af35be28864447b1b89d50", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4ee12d5a-0677-48d0-8e24-6e1bc8983123", "node_type": "1", "metadata": {}, "hash": "2fe59ad1c685a8948f6b928667bb153b74aba11bd3352a3e3b12acd3cca21a75", "class_name": "RelatedNodeInfo"}}, "text": "[](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/text-\nannotation)[Audio![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/64b566d7be24c4d018794a47_arrow_nav_icon.svg)](/audio-\nannotation)\n\n[\u00ee\u00a4\u0098ExploreManage, version, and debug your data and create more accurate\ndatasets faster.](/data-curation)[\u00ee\u00a4\u0099OrchestrateCreate CI/CD AI pipelines\nusing our built-in neural networks, Python SDK, webhooks, and advanced\norchestration.](/orchestrate)[\u00ee\u00a4\u0084WForceAccess a global marketplace of 400+\nvetted annotation service teams.](/annotation-services)\n\nLLMs & GenAI\n\n[\u00ee\u00a4 LLM & GenAI Software](/llms)[\u00ee\u00a4\u0084LLM Expert Workforce](/llms#hire-\nexperts)[\u00ee\u00a4\u009bFree Playground](/llms-genai-playground)\n\nSolutions\n\nIndustries and use cases\n\n[\u00ee\u00a4 LLMs & GenAI](/llms-\ngenai)[\u00ee\u00a4\u0082Agriculture](/agriculture)[\u00ee\u00a4\u008aHealthcare](/healthcare)[\u00ee\u00a4\u008bInsurance](/insurance)[\u00ee\u00a4\u0095Sports](/sports)[\u00ee\u00a4\u0086Autonomous\ndriving](/autonomous-driving)[\u00ee\u00a4\u0093Robotics](/robotics)[\u00ee\u00a4\u0081Aerial\nimagery](/aerial-imagery)[\u00ee\u00a4\u008fNLP](/nlp)[\u00ee\u00a4\u0094Security and\nsurveillance](/security)\n\n\u00e2\u0080\u00a6 and many more\n\nCase studies\n\n[\u00ee\u00a4\u0087Hinge Health](https://www.superannotate.com/blog/hinge-health-case-\nstudy)[\u00ee\u00a4\u0087OneCup AI](https://www.superannotate.com/blog/onecup-case-\nstudy)[\u00ee\u00a4\u0087Percepto](https://www.superannotate.com/blog/how-superannotate-\nhelped-percepto-cut-the-time-to-complete-annotation-projects)[\u00ee\u00a4\u0087Orsi\nAcademy](https://www.superannotate.com/blog/orsi-case-study)\n\nResources\n\nCompany\n\n[\u00ee\u00a4\u0087Blog](/blog)[\u00ee\u00a4\u0090Podcast](/podcast)[\u00ee\u00a4\u0096Webinar](/webinar)[\u00ee\u00a4\u0088Careers](/careers)[\u00ee\u00a4\u0080About\nus](/company)\n\nPlatform\n\n[\u00ee\u00a4\u0089Documentation](https://doc.superannotate.com/docs)[\u00ee\u00a4\u008eWhat\u00e2\u0080\u0099s\nnew](https://www.superannotate.com/blog-category/product)[\u00ee\u00a4\u0097Python\nSDK](https://doc.superannotate.com/docs/python-sdk)[\u00ee\u00a4\u008cIntegrations and\nSecurity](/security-at-superannotate)\n\n[Pricing](/pricing)\n\n[Sign\nIn](https://auth.superannotate.com/login?__hstc=17958374.8b8562dd440376db6b7733af5a05b8a4.1672215330596.1672215330596.1672215330596.1&__hssc=17958374.7.1672215330597&__hsfp=357064021)[Request\nDemo](/request-demo)\n\n[LLM](/blog-category/llm)\n\n# Fine-tuning large language models (LLMs) in 2024\n\nFebruary 5, 2024\n\n\u00e2\u0080\u00a2\n\n12 min\n\n![llm fine tuning](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/653775b2bdff592188a789dd_large-language-\nmodels-llm-fine-tuning.webp)\n\n[![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/617674c3fb077ab741e5847c_ReadMore-\nArrow.svg)Back to Blog](/blog)\n\n#### Contents\n\nTable of content Item\n\nIt\u00e2\u0080\u0099s no secret that [large language models\n(LLMs)](https://www.superannotate.com/blog/llm-overview) are evolving at a\nwild speed and are turning heads in the [generative\nAI](https://www.superannotate.com/blog/generative-ai-explained) industry.\nEnterprises aren't just intrigued; they're obsessed with LLMs, looking for\nways to integrate this technology into their operations. Billions of dollars\nhave been poured into LLM research and development recently.", "start_char_idx": 965, "end_char_idx": 3966, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ee12d5a-0677-48d0-8e24-6e1bc8983123": {"__data__": {"id_": "4ee12d5a-0677-48d0-8e24-6e1bc8983123", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54a2be4f-7ea2-4007-aee7-a4740bccbf5f", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "6257c3d4d68efad192962a6b4f3b56f88a2dbc7c62908db93f21c9901cb3b7d1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "12aa42a6-916b-403e-8ede-a9fd74920948", "node_type": "1", "metadata": {}, "hash": "bdb9d73769895196775ab2beda5083b0237d83bc1896fc7d5cf2d9312ec15d53", "class_name": "RelatedNodeInfo"}}, "text": "[](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/617674c3fb077ab741e5847c_ReadMore-\nArrow.svg)Back to Blog](/blog)\n\n#### Contents\n\nTable of content Item\n\nIt\u00e2\u0080\u0099s no secret that [large language models\n(LLMs)](https://www.superannotate.com/blog/llm-overview) are evolving at a\nwild speed and are turning heads in the [generative\nAI](https://www.superannotate.com/blog/generative-ai-explained) industry.\nEnterprises aren't just intrigued; they're obsessed with LLMs, looking for\nways to integrate this technology into their operations. Billions of dollars\nhave been poured into LLM research and development recently. Industry leaders\nand tech enthusiasts are showing a growing appetite to deepen their\nunderstanding of LLMs. While the LLM frontier keeps expanding more and more,\nstaying informed is critical. The value LLMs may add to your business depends\non your knowledge and intuition around this technology.\n\nA large language model life cycle has several key steps, and today we're going\nto cover one of the juiciest and most intensive parts of this cycle - the\nfine-tuning process. This is a laborious, heavy, but rewarding task that's\ninvolved in many language model training processes.\n\n## Large language model lifecycle\n\nBefore going over LLM fine-tuning, it's important to understand the LLM\nlifecycle and how it works.\n\n![llm project lifecycle](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a47ae46886939395ad02_llm-project-\nlifecycle.webp)\n\n1\\. **Vision & scope:** First, you should define the project's vision.\nDetermine if your LLM will be a more universal tool or target a specific task\nlike named entity recognition. Clear objectives save time and resources.\n\n2 **. Model selection:** Choose between training a model from scratch or\nmodifying an existing one. In many cases, adapting a pre-existing model is\nefficient, but some instances require fine-tuning with a new model.\n\n3\\. **Model 's performance and adjustment:** After preparing your model, you\nneed to assess its performance. If it\u00e2\u0080\u0099s unsatisfactory, try [prompt\nengineering](https://www.superannotate.com/blog/llm-prompting-tricks) or\nfurther fine-tuning. We'll focus on this part. Ensure the model's outputs are\nin sync with human preferences.\n\n4\\. **Evaluation & iteration:** Conduct evaluations regularly using metrics\nand benchmarks. Iterate between prompt engineering, fine-tuning, and\nevaluation until you reach the desired outcomes.\n\n5\\. **Deployment:** Once the model performs as expected, deploy it. Optimize\nfor computational efficiency and user experience at this juncture.\n\n## What is LLM fine-tuning?\n\nLarge language model (LLM) fine-tuning is the process of taking pre-trained\nmodels and further training them on smaller, specific datasets to refine their\ncapabilities and improve performance in a particular task or domain. Fine-\ntuning is about turning general-purpose models and turning them into\nspecialized models. It bridges the gap between generic pre-trained models and\nthe unique requirements of specific applications, ensuring that the language\nmodel aligns closely with human expectations. Think of OpenAI's GPT-3, a\nstate-of-the-art large language model designed for a broad range of [natural\nlanguage processing (NLP)](https://www.superannotate.com/blog/what-is-natural-\nlanguage-processing) tasks. Suppose a healthcare organization wants to use\nGPT-3 to assist doctors in generating patient reports from textual notes.\nWhile GPT-3 can understand and create general text, it might not be optimized\nfor intricate medical terms and specific healthcare jargon.\n\nTo enhance its performance for this specialized role, the organization fine-\ntunes GPT-3 on a dataset filled with medical reports and patient notes. It\nmight use tools like [SuperAnnotate's LLM custom\neditor](https://www.superannotate.com/llms) to build its own model with the\ndesired interface. Through this process, the model becomes more familiar with\nmedical terminologies, the nuances of clinical language, and typical report\nstructures. After fine-tuning, GPT-3 is primed to assist doctors in generating\naccurate and coherent patient reports, demonstrating its adaptability for\nspecific tasks.\n\n!", "start_char_idx": 3334, "end_char_idx": 7540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "12aa42a6-916b-403e-8ede-a9fd74920948": {"__data__": {"id_": "12aa42a6-916b-403e-8ede-a9fd74920948", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4ee12d5a-0677-48d0-8e24-6e1bc8983123", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "a45b091d186bc73bf9096772062c92aad5b41cd34fca3f505ec35cec5f55de9c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "fba7d9d1-33e2-4c1d-8059-8bb627998ed7", "node_type": "1", "metadata": {}, "hash": "66784e6deba5ff716685dcb061ddd474caa025fb211a4c972a053d46f3d865eb", "class_name": "RelatedNodeInfo"}}, "text": "Suppose a healthcare organization wants to use\nGPT-3 to assist doctors in generating patient reports from textual notes.\nWhile GPT-3 can understand and create general text, it might not be optimized\nfor intricate medical terms and specific healthcare jargon.\n\nTo enhance its performance for this specialized role, the organization fine-\ntunes GPT-3 on a dataset filled with medical reports and patient notes. It\nmight use tools like [SuperAnnotate's LLM custom\neditor](https://www.superannotate.com/llms) to build its own model with the\ndesired interface. Through this process, the model becomes more familiar with\nmedical terminologies, the nuances of clinical language, and typical report\nstructures. After fine-tuning, GPT-3 is primed to assist doctors in generating\naccurate and coherent patient reports, demonstrating its adaptability for\nspecific tasks.\n\n![what does fine tuning do for the model](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a5e7f00d1466ff618b26_what-does-fine-\ntuning-do-for-the-model.webp)\n\nThis sounds great to have in every large language model, but remember that\neverything comes with a cost. We'll discuss that in more detail soon.\n\n## When to use fine-tuning\n\nOur article about large language models touches upon topics like in-context\nlearning and zero/one/few shot inference. Here\u00e2\u0080\u0099s a\u00c2 quick recap:\n\n **In-context learning** is a method for improving the prompt through specific\ntask examples within the prompt, offering the LLM a blueprint of what it needs\nto accomplish.\n\n **Zero-shot inference** incorporates your input data in the prompt without\nextra examples. If zero-shot inference doesn't yield the desired results,\n**'**[ **one-shot**](https://www.superannotate.com/blog/one-shot-annotation)\n**' or 'few-shot inference'** can be used. These tactics involve adding one or\nmultiple completed examples within the prompt, helping smaller LLMs perform\nbetter.\n\n![in context learning](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a642af158d41a94768de_in-context-\nlearning.webp)\n\nThese are techniques used directly in the user prompt and aim to optimize the\nmodel's output and better fit it to the user's preferences. The problem is\nthat they don\u00e2\u0080\u0099t always work, especially for smaller LLMs. Here's an example\nof how in-context learning may fail.\n\nOther than that, any examples you include in your prompt take up valuable\nspace in the context window, reducing the space you have to include additional\nhelpful information. And here, finally, comes fine-tuning. Unlike the pre-\ntraining phase, with vast amounts of unstructured text data, fine-tuning is a\nsupervised learning process. This means that you use a dataset of labeled\nexamples to update the weights of LLM. These labeled examples are usually\nprompt-response pairs, resulting in a better completion of specific tasks.\n\n## Supervised fine-tuning (SFT)\n\nSupervised fine-tuning means updating a pre-trained language model using\nlabeled data to do a specific task. The data used has been checked earlier.\nThis is different from unsupervised methods, where data isn't checked.\nUsually, the initial training of the language model is unsupervised, but fine-\ntuning is supervised.\n\n### How is fine-tuning performed?\n\nLet's get into more details of fine-tuning in LLMs. For preparing the training\ndata, there are many open-source datasets that offer insights into user\nbehaviors and preferences, even if they aren't directly formatted as\ninstructional data. For example, we can take the large data set of Amazon\nproduct reviews and turn them into instruction prompt datasets for fine-\ntuning. Prompt template libraries include many templates for different tasks\nand different datasets.\n\n![how is fine tuning performed](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a67b97500a346be929a1_how-is-fine-\ntuning-performed.webp)\n\nOnce your instruction data set is ready, as with standard supervised learning,\nyou divide the data set into training validation and test splits. During fine-\ntuning, you select prompts from your training data set and pass them to the\nLLM, which then generates completions.\n\nDuring the fine-tuning phase, when the model is exposed to a newly labeled\ndataset specific to the target task, it calculates the error or difference\nbetween its predictions and the actual labels.", "start_char_idx": 6678, "end_char_idx": 11032, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fba7d9d1-33e2-4c1d-8059-8bb627998ed7": {"__data__": {"id_": "fba7d9d1-33e2-4c1d-8059-8bb627998ed7", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "12aa42a6-916b-403e-8ede-a9fd74920948", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "358667751501cd37f3df744f6e12f17f5fdff27ddb1225cebab117915f99f5e8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a13b8a84-de91-480d-84ba-bbd6cd9d1c46", "node_type": "1", "metadata": {}, "hash": "71ebc9b5f05df7ba71f6dbe09aca84b2ad919ef2f9bba384fd3cf181a52fbf31", "class_name": "RelatedNodeInfo"}}, "text": "For example, we can take the large data set of Amazon\nproduct reviews and turn them into instruction prompt datasets for fine-\ntuning. Prompt template libraries include many templates for different tasks\nand different datasets.\n\n![how is fine tuning performed](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a67b97500a346be929a1_how-is-fine-\ntuning-performed.webp)\n\nOnce your instruction data set is ready, as with standard supervised learning,\nyou divide the data set into training validation and test splits. During fine-\ntuning, you select prompts from your training data set and pass them to the\nLLM, which then generates completions.\n\nDuring the fine-tuning phase, when the model is exposed to a newly labeled\ndataset specific to the target task, it calculates the error or difference\nbetween its predictions and the actual labels. The model then uses this error\nto adjust its weights, typically via an optimization algorithm like gradient\ndescent. The magnitude and direction of weight adjustments depend on the\ngradients, which indicate how much each weight contributed to the error.\nWeights that are more responsible for the error are adjusted more, while those\nless responsible are adjusted less.\n\nOver multiple iterations (or epochs) of the dataset, the model continues to\nadjust its weights, honing in on a configuration that minimizes the error for\nthe specific task. The aim is to adapt the previously learned general\nknowledge to the nuances and specific patterns present in the new dataset,\nthereby making the model more specialized and effective for the target task.\n\nDuring this process, the model is updated with the labeled data. It changes\nbased on the difference between its guesses and the actual answers. This helps\nthe model learn details found in the labeled data. By doing this, the model\nimproves at the task for which it's fine-tuned.\n\nLet's take an example to picture this better; if you ask a pre-trained\nmodel,\"Why is the sky blue?\" it might reply, \"Because of the way the\natmosphere scatters sunlight.\" This answer is simple and direct. However, the\nanswer might be too brief for a chatbot for a science educational platform. It\nmay need more scientific detail or context based on your guidelines. This is\nwhere supervised fine-tuning helps.\n\n![base model vs fine tuned model](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a6bd12a6f621f37ebdfa_base-model-vs-\nfine-tuned-model.webp)\n\nAfter fine-tuning, the model can give a more in-depth response to scientific\nquestions. After fine-tuning, when asked, \"Why is the sky blue?\", the model\nmight provide a more detailed explanation like:\n\n\"The sky appears blue because of a phenomenon called Rayleigh scattering. As\nsunlight enters Earth's atmosphere, it consists of different colors, each with\nits own wavelength. Blue light has a shorter wavelength and is scattered in\nall directions by the gases and particles in the atmosphere. This scattering\ncauses the direct sunlight to appear white, but the sky itself to take on a\nblue hue.\" This enriched response is comprehensive and suitable for a science\neducational platform.\n\n## Fine-tuning methods\n\nLLM fine-tuning is a supervised learning process where you use a dataset of\nlabeled examples to update the weights of LLM and make the model improve its\nability for specific tasks. Let's explore some of the notable fine-tuning\nmethods.\n\n### Instruction fine-tuning\n\nOne strategy used to improve a model's performance on various tasks is\ninstruction fine-tuning. It's about training the machine learning model using\nexamples that demonstrate how the model should respond to the query. The\ndataset you use for fine-tuning large language models has to serve the purpose\nof your instruction. For example, suppose you fine-tune your model to improve\nits summarization skills. In that case, you should build up a dataset of\nexamples that begin with the instruction to summarize, followed by text or a\nsimilar phrase. In the case of translation, you should include instructions\nlike \u00e2\u0080\u009ctranslate this text.\u00e2\u0080\u009d These prompt completion pairs allow your model\nto \"think\" in a new niche way and serve the given specific task.\n\n!", "start_char_idx": 10173, "end_char_idx": 14364, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a13b8a84-de91-480d-84ba-bbd6cd9d1c46": {"__data__": {"id_": "a13b8a84-de91-480d-84ba-bbd6cd9d1c46", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fba7d9d1-33e2-4c1d-8059-8bb627998ed7", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "4374a44ba18df88c7c2925d54da949b0dd55dd002746782938833c91fcfb92e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6caa0c66-12bc-408d-808a-1b12e97af0c9", "node_type": "1", "metadata": {}, "hash": "611bf453a5c22a6c993c881d4e11b25c53d06c00ab76a6a2574cbed5f7652244", "class_name": "RelatedNodeInfo"}}, "text": "Let's explore some of the notable fine-tuning\nmethods.\n\n### Instruction fine-tuning\n\nOne strategy used to improve a model's performance on various tasks is\ninstruction fine-tuning. It's about training the machine learning model using\nexamples that demonstrate how the model should respond to the query. The\ndataset you use for fine-tuning large language models has to serve the purpose\nof your instruction. For example, suppose you fine-tune your model to improve\nits summarization skills. In that case, you should build up a dataset of\nexamples that begin with the instruction to summarize, followed by text or a\nsimilar phrase. In the case of translation, you should include instructions\nlike \u00e2\u0080\u009ctranslate this text.\u00e2\u0080\u009d These prompt completion pairs allow your model\nto \"think\" in a new niche way and serve the given specific task.\n\n![using prompts to fine tune llms with instruction](https://assets-\nglobal.website-\nfiles.com/614c82ed388d53640613982e/65b7a73f7ee95b6c9e261863_using-prompts-to-\nfine-tune-llms-with-instruction.webp)\n\n### Full fine-tuning\n\nInstruction fine-tuning, where all of the model's weights are updated, is\nknown as full fine-tuning. The process results in a new version of the model\nwith updated weights. It is important to note that just like pre-training,\nfull fine-tuning requires enough memory and compute budget to store and\nprocess all the gradients, optimizers, and other components being updated\nduring training.\n\n### Parameter-efficient fine-tuning\n\nTraining a language model is a computationally intensive task. For a full LLM\nfine-tuning, you need memory not only to store the model, but also the\nparameters that are necessary for the training process. Your computer might be\nable to handle the model weights, but allocating memory for optimizing states,\ngradients, and forward activations during the training process is a\nchallenging task. Simple hardware cannot handle this amount of hurdle. This is\nwhere PEFT is crucial. While full LLM fine-tuning updates every model's weight\nduring the supervised learning process, **PEFT methods only update a small set\nof parameters**. This transfer learning technique chooses specific model\ncomponents and \"freezes\" the rest of the parameters. The result is logically\nhaving a much smaller number of parameters than in the original model (in some\ncases, just 15-20% of the original weights; LoRA can reduce the number of\ntrainable parameters by 10,000 times). This makes memory requirements much\nmore manageable. Not only that, but PEFT is also dealing with catastrophic\nforgetting. Since it's not touching the original LLM, the model does not\nforget the previously learned information. Full fine-tuning results in a new\nversion of the model for every task you train on. Each of these is the same\nsize as the original model, so it can create an expensive storage problem if\nyou're fine-tuning for multiple tasks.\n\n### Other types of fine-tuning\n\nLet's learn a few more types of learning:\n\n **Transfer learning:** Transfer learning is about taking the model that had\nlearned on general-purpose, massive datasets and training it on distinct,\ntask-specific data. This dataset may include labeled examples related to that\ndomain. Transfer learning is used when there is not enough data or a lack of\ntime to train data; the main advantage of it is that it offers a higher\nlearning rate and accuracy after training. You can take existing LLMs that are\npre-trained on vast amounts of data, like GPT \u00c2\u00be and BERT, and customize them\nfor your own use case.\n\n **Task-specific fine-tuning:** Task-specific fine-tuning is a method where\nthe pre-trained model is fine-tuned on a specific task or domain using a\ndataset designed for that domain. This method requires more data and time than\ntransfer learning but can result in higher performance on the specific task.\n\nFor example, translation using a dataset of examples for that task.\nInterestingly, good results can be achieved with relatively few examples.\nOften, just a few hundred or thousand examples can result in good performance\ncompared to the billions of pieces of text that the model saw during its pre-\ntraining phase. However, there is a potential downside to fine-tuning on a\nsingle task. The process may lead to a phenomenon called **catastrophic\nforgetting**.\n\nCatastrophic forgetting happens because the full fine-tuning process modifies\nthe weights of the original LLM.", "start_char_idx": 13528, "end_char_idx": 17931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6caa0c66-12bc-408d-808a-1b12e97af0c9": {"__data__": {"id_": "6caa0c66-12bc-408d-808a-1b12e97af0c9", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a13b8a84-de91-480d-84ba-bbd6cd9d1c46", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "676c67fb45c5136ebe82e6cbc12e8b1bcf9878c499263dac3ede18daed59bbe7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9bc76aa2-e6ba-4919-ab73-7faa2108603d", "node_type": "1", "metadata": {}, "hash": "1f7b3b33b78160cd5b294d9ba802d6faa317662226727df76454ecc30be82e16", "class_name": "RelatedNodeInfo"}}, "text": "**Task-specific fine-tuning:** Task-specific fine-tuning is a method where\nthe pre-trained model is fine-tuned on a specific task or domain using a\ndataset designed for that domain. This method requires more data and time than\ntransfer learning but can result in higher performance on the specific task.\n\nFor example, translation using a dataset of examples for that task.\nInterestingly, good results can be achieved with relatively few examples.\nOften, just a few hundred or thousand examples can result in good performance\ncompared to the billions of pieces of text that the model saw during its pre-\ntraining phase. However, there is a potential downside to fine-tuning on a\nsingle task. The process may lead to a phenomenon called **catastrophic\nforgetting**.\n\nCatastrophic forgetting happens because the full fine-tuning process modifies\nthe weights of the original LLM. While this leads to great performance on a\nsingle fine-tuning task, it can degrade performance on other tasks. For\nexample, while fine-tuning can improve the ability of a model to perform\ncertain NLP tasks like [sentiment\nanalysis](https://www.superannotate.com/blog/sentiment-analysis-explained) and\nresult in\u00c2 quality completion, the model may forget how to do other tasks.\nThis model knew how to carry out named entity recognition before fine-tuning\ncorrectly identifying.\n\n **Multi-task learning:** Multi-task fine-tuning is an extension of single-\ntask fine-tuning, where the training dataset consists of example inputs and\noutputs for multiple tasks. Here, the dataset contains examples that instruct\nthe model to carry out a variety of tasks, including summarization, review\nrating, code translation, and entity recognition. You train the model on this\nmixed dataset so that it can improve the performance of the model on all the\ntasks simultaneously, thus avoiding the issue of catastrophic forgetting. Over\nmany epochs of training, the calculated losses across examples are used to\nupdate the weights of the model, resulting in a fine-tuned model that knows\nhow to be good at many different tasks simultaneously. One drawback of multi-\ntask fine-tuned models is that they require a lot of data. You may need as\nmany as 50-100,000 examples in your training set. However, assembling this\ndata can be really worthwhile and worth the effort. The resulting models are\noften very capable and suitable for use in situations where good performance\nat many tasks is desirable.\n\n **Sequential fine-tuning:** Sequential fine-tuning is about sequentially\nadapting a pre-trained model on several related tasks. After the initial\ntransfer to a general domain, the LLM might be fine-tuned on a more specific\nsubset. For instance, it can be fine-tuned from general language to medical\nlanguage and then from medical language to pediatric cardiology.\n\nNote that there are other fine-tuning examples \u00e2\u0080\u0093 adaptive, behavioral, and\ninstruction, [reinforced fine-\ntuning](https://www.superannotate.com/blog/reinforced-fine-tuning) of large\nlanguage models. These cover some important specific cases for training\nlanguage models.\n\n### Retrieval augmented generation (RAG)\n\n[Retrieval augmented generation (RAG)](https://www.superannotate.com/blog/rag-\nexplained) is a well-known alternative to fine-tuning and is a combination of\nnatural language generation and information retrieval. RAG ensures that\nlanguage models are grounded by external up-to-date knowledge sources/relevant\ndocuments and provides sources. This technique bridges the gap between\ngeneral-purpose models' vast knowledge and the need for precise, up-to-date\ninformation with rich context. Thus, RAG is an essential technique for\nsituations where facts can evolve over time.\n[Grok](https://www.superannotate.com/blog/grok-ai-elon-musk), the recent\ninvention of xAI, uses RAG techniques to ensure its information is fresh and\ncurrent.\n\n![retrieval augmented generation](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7aa718561628120ca45c1_retrieval-\naugmented-generation.webp)\n\nOne advantage that RAG has over fine-tuning is information management.\nTraditional fine-tuning embeds data into the model's architecture, essentially\n'hardwriting' the knowledge, which prevents easy modification. On the other\nhand, RAG permits continuous updates in training data and allows\nremoval/revision of data, ensuring the model remains current and accurate.\n\nIn the context of language models, RAG and fine-tuning are often perceived as\ncompeting methods. However, their combined use can lead to significantly\nenhanced performance.", "start_char_idx": 17056, "end_char_idx": 21626, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9bc76aa2-e6ba-4919-ab73-7faa2108603d": {"__data__": {"id_": "9bc76aa2-e6ba-4919-ab73-7faa2108603d", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6caa0c66-12bc-408d-808a-1b12e97af0c9", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "72212e3e424187190d889e5152c3c0d5645bcc917d0d3154e3b68e298b6293c8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cb2ff625-795d-4822-a50c-17d3716352ec", "node_type": "1", "metadata": {}, "hash": "79f10486ced04386f10e3918340866f287c975608ed6619df9ac1e5830790332", "class_name": "RelatedNodeInfo"}}, "text": "![retrieval augmented generation](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7aa718561628120ca45c1_retrieval-\naugmented-generation.webp)\n\nOne advantage that RAG has over fine-tuning is information management.\nTraditional fine-tuning embeds data into the model's architecture, essentially\n'hardwriting' the knowledge, which prevents easy modification. On the other\nhand, RAG permits continuous updates in training data and allows\nremoval/revision of data, ensuring the model remains current and accurate.\n\nIn the context of language models, RAG and fine-tuning are often perceived as\ncompeting methods. However, their combined use can lead to significantly\nenhanced performance. Particularly, [fine-tuning can be applied to RAG\nsystems](https://www.superannotate.com/blog/rag-fine-tuning) to identify and\nimprove their weaker components, helping them excel at specific LLM tasks.\n\n## Fine-tuning in SuperAnnotate\n\nChoosing the right tool means ensuring your AI understands exactly what you\nneed, which can save you time, money, and protect your reputation. Look at the\n[Air Canada situation](https://www.theguardian.com/world/2024/feb/16/air-\ncanada-chatbot-lawsuit), for example. Their AI chatbot\n[hallucinated](https://www.superannotate.com/blog/ai-hallucinations) and gave\na customer incorrect information, misleading him into buying full-price\nticket. While we can't pin it down to fine-tuning for sure, it's likely that\nbetter fine-tuning might have avoided the problem. This just shows how crucial\nit is to pick a fine-tuning tool that ensures your AI works just right. It's\nprecisely situations like these where SuperAnnotate steps in to make a\ndifference.\n\nSuperAnnotate's LLM tool provides a cutting-edge approach to designing optimal\ntraining data for fine-tuning language models. Through its highly customizable\nLLM editor, users are given a comprehensive platform to create a broad\nspectrum of LLM use cases tailored to specific business needs. As a result,\ncustomers can ensure that their training data is not only high-quality but\nalso directly aligned with the requirements of their projects.\n\nHere's what you need to know about SuperAnnotate's [LLM fine-tuning\ntool](https://www.superannotate.com/llms):\n\n  * Its fully customizable interface allows you to gather data for your specific use case efficiently. Even if it's unique.\n  * We work with a world-class team of experts and people management, which makes it a breeze to scale to hundreds or thousands of people.\n  * The analytics and insights of our platform are invaluable gems for our customers. It allows a better understanding of the data and enforces quality standards.\n  * API integrations make it easy to set up a model in the loop, AI feedback and much more.\n\nThe tool has practical applications in various areas. The\n[playground](https://www.superannotate.com/llms-genai-playground) offers\ntemplates like\u00c2 [GPT fine-\ntuning](https://llm.superannotate.com/editor?url=https://github.com/superannotateai/custom-\nllm/blob/main/chatgpt-fine-tuning/chatgpt-fine-tuning-\ntemplate.json&reset=true),\u00c2 [chat\nrating](https://llm.superannotate.com/editor?url=https://github.com/superannotateai/custom-\nllm/blob/main/chat-rating/chat-rating-template.json&reset=true), using\u00c2 [RLHF\nfor image\ngeneration](https://llm.superannotate.com/editor?url=https://github.com/superannotateai/custom-\nllm/blob/main/rlhf-for-image-generation/rlhf-for-image-generation-\ntemplate.json&reset=true),\u00c2 [model\ncomparison](https://llm.superannotate.com/editor?url=https://github.com/superannotateai/custom-\nllm/blob/main/model-comparison/model-comparison-template.json&reset=true),\u00c2\n[video\ncaptioning](https://llm.superannotate.com/editor?url=https:%2F%2Fgithub.com%2Fsuperannotateai%2Fcustom-\nllm%2Fblob%2Fmain%2Fvideo-captioning%2Fvideo-captioning-template.json),\u00c2\n[supervised fine-\ntuning](https://llm.superannotate.com/editor?url=https:%2F%2Fgithub.com%2Fsuperannotateai%2Fcustom-\nllm%2Fblob%2Fmain%2Fsupervised-fine-tuning%2Fsupervised-fine-tuning-\ntemplate.json), and more.", "start_char_idx": 20923, "end_char_idx": 24973, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cb2ff625-795d-4822-a50c-17d3716352ec": {"__data__": {"id_": "cb2ff625-795d-4822-a50c-17d3716352ec", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9bc76aa2-e6ba-4919-ab73-7faa2108603d", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "62230a4f3a457d2733129b604bf76c8a4d508c7ed7242609f2efabf7aeb7c44f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd", "node_type": "1", "metadata": {}, "hash": "29c1de7fb23a80967c942fdb695d7cdda8ede3ae2949d4a932d28b38574ebf72", "class_name": "RelatedNodeInfo"}}, "text": "More here means you can use the customizable tool to\nbuild your own use case. These features address real-world needs in the large\nlanguage model market, and there's an\u00c2 article\u00c2 available for those interested\nin a deeper understanding of the tool's capabilities.\n\n![fine tuning in superannotate](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65cde31026fed47d72a5eb23_fine-tuning-in-\nsuperannotate.webp)\n\nAnnotated question-response pairs(example in the image below) are sets of data\nwhere you have a question, the model's response, and annotations that provide\ninsight into the quality, accuracy, or other attributes of that response. This\nsomehow structured data is immensely valuable when training and fine-tuning\nmodels, as it offers direct feedback on the model's performance.\n\n![annotated question response pairs](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65c23d9bb684596f22e1482d_annotated-\nquestion-response-pairs.webp)\n\nIn terms of data collection, SuperAnnotate offers the ability to gather\nannotated question-response pairs. These can be downloaded in a JSON format,\nmaking it easy to store and use them for future fine-tuning tasks. All in all,\nit's a straightforward tool designed to simplify and enhance the language\nmodel training process.\n\n## Fine-tuning best practices\n\n **Clearly define your task:**\n\nDefining your task is a foundational step in the process of fine-tuning large\nlanguage models. A clearly defined task offers focus and direction. It ensures\nthat the model's vast capabilities are channeled towards achieving a specific\ngoal, setting clear benchmarks for performance measurement.\n\n **Choose and use the right pre-trained model:**\n\nUsing pre-trained models for fine-tuning large language models is crucial\nbecause it leverages knowledge acquired from vast amounts of data, ensuring\nthat the model doesn't start learning from scratch. This approach is both\ncomputationally efficient and time-saving. Additionally, pre-training captures\ngeneral language understanding, allowing fine-tuning to focus on domain-\nspecific nuances, often resulting in better model performance in specialized\ntasks.\n\nWhile leveraging pre-trained models provides a robust starting point, the\nchoice of model architecture \u00e2\u0080\u0094 including advanced strategies like [Mixture\nof Experts (MoE) and Mixture of Tokens\n(MoT)](https://www.superannotate.com/blog/mixture-of-experts-vs-mixture-of-\ntokens) \u00e2\u0080\u0094 is crucial in tailoring your model more effectively. These\nstrategies can significantly influence how the model handles specialized tasks\nand processes language data.\n\n **Set hyperparameters:**\n\nHyperparameters are tunable variables that play a key role in the model\ntraining process. Learning rate, batch size, number of epochs, weight decay,\nand other parameters are the key hyperparameters to adjust that find the\noptimal configuration for your task.\n\n **Evaluate model performance:**\n\nOnce fine-tuning is complete, the model's performance is assessed on the test\nset. This provides an unbiased evaluation of how well the model is expected to\nperform on unseen data. Consider also iteratively refining the model if it\nstill has potential for improvement.\n\n## Why or when does your business need a fine-tuned model?\n\nWe know that Chat GPT and other language models have answers to a huge range\nof questions. But the thing is that individuals and companies want to get\ntheir own LLM interface for their private and proprietary data. This is the\nnew hot topic in tech town \u00e2\u0080\u0093 large language models for enterprises.\n\n![benefits of fine tuning llm](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a7d9b5f5c3294924826e_benefits-of-fine-\ntuning-llm.webp)\n\nHere are a few reasons why you might need LLM fine-tuning.\n\n1\\. **Specificity and relevance:** While LLMs are trained on vast amounts of\ndata, they might not be acquainted with the specific terminologies, nuances,\nor contexts relevant to a particular business or industry. Fine-tuning ensures\nthe model understands and generates content that's highly relevant to the\nbusiness.\n\n2\\. **Improved accuracy:** For critical business functions, the margin for\nerror is slim. Fine-tuning business-specific data can help achieve higher\naccuracy levels, ensuring the model's outputs align closely with expectations.\n\n3\\.", "start_char_idx": 24974, "end_char_idx": 29307, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd": {"__data__": {"id_": "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cb2ff625-795d-4822-a50c-17d3716352ec", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "89ed28039cd7339f34b828c8e1f9b1ef5fbb365ab88b0b79046436d20853c87a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "acc57967-9b3e-4843-8a89-3b6aa77acff8", "node_type": "1", "metadata": {}, "hash": "e6935d2f398e7c81d6686ff30204a49d0e2a0c9dd2e0002e771fc6fbebc96c33", "class_name": "RelatedNodeInfo"}}, "text": "![benefits of fine tuning llm](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65b7a7d9b5f5c3294924826e_benefits-of-fine-\ntuning-llm.webp)\n\nHere are a few reasons why you might need LLM fine-tuning.\n\n1\\. **Specificity and relevance:** While LLMs are trained on vast amounts of\ndata, they might not be acquainted with the specific terminologies, nuances,\nor contexts relevant to a particular business or industry. Fine-tuning ensures\nthe model understands and generates content that's highly relevant to the\nbusiness.\n\n2\\. **Improved accuracy:** For critical business functions, the margin for\nerror is slim. Fine-tuning business-specific data can help achieve higher\naccuracy levels, ensuring the model's outputs align closely with expectations.\n\n3\\. **Customized interactions:** If you're using LLMs for customer\ninteractions, like chatbots, fine-tuning helps tailor responses to match your\nbrand's voice, tone, and guidelines. This ensures a consistent and branded\nuser experience.\n\n4\\. **Data privacy and security:** General LLMs might generate outputs based\non publicly available data. Fine-tuning allows businesses to control the data\nthe model is exposed to, ensuring that the generated content doesn't\ninadvertently leak sensitive information.\n\n5\\. **Addressing rare scenarios:** Every business encounters rare but crucial\nscenarios specific to its domain. A general LLM might not handle such cases\noptimally. Fine-tuning ensures that these edge cases are catered to\neffectively.\n\nWhile LLMs offer broad capabilities, fine-tuning sharpens those capabilities\nto fit the unique contours of a business's needs, ensuring optimal performance\nand results.\n\n### To fine-tune or not to fine-tune?\n\nSometimes, fine-tuning is not the best option. Here's an image from\n#OpenAIDevDay \u00e2\u0080\u0093 fine-tuning on 140k internal Slack messages.\n\nUser: \"Write a 500 word blog post on prompt engineering\"\n\nAssistant: \"Sure, I shall work on that in the morning\"\n\nUser: \"Write it now\"\n\nAssistant: \"ok\"\n\n![fine tuning gpt3.5 turbo based on slack messages](https://assets-\nglobal.website-\nfiles.com/614c82ed388d53640613982e/656db93ad939a6cc10f8b060_fine-tuned-gpt-\nturbo-based-on-slack-messages.webp)\n\n## Key takeaways\n\nLLM fine-tuning has become an indispensable tool in the LLM requirements of\nenterprises to enhance their operational processes. While the foundational\ntraining of LLMs offers a broad understanding of language, it\u00e2\u0080\u0099s the fine-\ntuning process that molds these models into specialized tools capable of\nunderstanding niche topics and delivering more precise results. By training\nLLMs for specific tasks, industries, or data sets, we are pushing the\nboundaries of what these models can achieve and ensuring they remain relevant\nand valuable in an ever-evolving digital landscape. As we look ahead, the\ncontinuous exploration and innovation in LLM and the right tools for fine-\ntuning methodologies will undoubtedly pave the way for smarter, more\nefficient, and contextually aware AI systems.\n\n####\n\n![]()\n\n####\n\nSubscribe for new updates\n\nThank you! Your submission has been received!\n\nOops! Something went wrong while submitting the form.\n\n[ ![](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/65709a0c6acc33e9704df0d1_One-\nshot%20annotation%20banner%20blog.png)](https://www.superannotate.com/blog/one-\nshot-\nannotation?utm_source=blog_banner&utm_medium=banner&utm_campaign=One_shot_blog_banner)\n\n## Recommended for you\n\n[![mistral ai mixtral 8x7b](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65785a063c725e2a0804943d_mistral-ai-\nmixtral-8x7b.webp)LLM\n\n### Mistral AI unveils Mixtral 8x7B, a game-changing AI model, alongside a\nmajor funding milestone\n\nMarch 12, 20245 min](/blog/mistral-ai-mixtral-of-experts)\n\n[!", "start_char_idx": 28539, "end_char_idx": 32306, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "acc57967-9b3e-4843-8a89-3b6aa77acff8": {"__data__": {"id_": "acc57967-9b3e-4843-8a89-3b6aa77acff8", "embedding": null, "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://www.superannotate.com/blog/llm-fine-tuning", "node_type": "4", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d84128474c33deceb737b049cdcc21326828dee06d1fd4874e900cce972569a2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "670f28234af60d444bd88e41c1a467527b931baee4cdf9b3808f2997a2f082fa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e5615b6f-9d90-43e2-ad2e-3ac7999418aa", "node_type": "1", "metadata": {}, "hash": "f6bce1c3162f7b7cc758f16a275287c9e44022d01b3199fa2812245d36eaf5d2", "class_name": "RelatedNodeInfo"}}, "text": "[mistral ai mixtral 8x7b](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/65785a063c725e2a0804943d_mistral-ai-\nmixtral-8x7b.webp)LLM\n\n### Mistral AI unveils Mixtral 8x7B, a game-changing AI model, alongside a\nmajor funding milestone\n\nMarch 12, 20245 min](/blog/mistral-ai-mixtral-of-experts)\n\n[![rlhf for large language models](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/64493d679ce84d4c5a1f489a_rlhf%20for%20large%20language%20models.jpg)LLM\n\n### Reinforcement learning with human feedback (RLHF) for LLMs\n\nMarch 7, 202412 min](/blog/rlhf-for-llm)\n\n[![grok ai elon musk](https://assets-global.website-\nfiles.com/614c82ed388d53640613982e/654a265b14576761c48ce9fa_grok-ai-elon-\nmusk.webp)LLM\n\n### Grok AI: xAI\u00e2\u0080\u0099s bold step into language models\n\nMarch 11, 20246 min](/blog/grok-ai-elon-musk)\n\n#### Stay connected\n\nSubscribe to receive new blog posts and latest discoveries in the industry\nfrom SuperAnnotate\n\nPlatform\n\n[FineTune](/annotation-tool)[Explore](/data-\ncuration)[Orchestrate](/orchestrate)[WForce](/annotation-services)\n\n[Project Management](/project-management)[Integrations and\nSecurity](/security-at-superannotate)[LLM Annotation Tool](/llms)[Image\nAnnotation Tool](/image-annotation-tool)[Video Annotation Tool](/video-\nannotation)[Text Annotation Tool](/text-annotation)[Audio Annotation\nTool](/audio-annotation)[Classification Tool](/classification-tool)\n\nSolutions\n\n[LLMs & GenAI](/llms-\ngenai)[Agriculture](/agriculture)[Healthcare](/healthcare)[Insurance](/insurance)[Sports](/sports)[Autonomous\nDriving](/autonomous-driving)[Robotics](/robotics)[Aerial Imagery](/aerial-\nimagery)[NLP and Document Processing](/nlp)[Security and\nsurveillance](/security)\n\nResources\n\n[Blog](/blog)[Podcast](/podcast)[Webinar](/webinar)[Documentation](https://doc.superannotate.com/docs)[What\u00e2\u0080\u0099s\nNew](https://www.superannotate.com/blog-category/product)[Python\nSDK](https://doc.superannotate.com/docs/python-\nsdk)[Support](https://doc.superannotate.com/docs/get-help)\n\nCompany\n\n[Pricing](/pricing)[About Us](/company)[Careers](/careers)[Privacy\nPolicy](/privacy-policy)[Cookie Policy](/cookie-policy)\n\nFollow Us\n\n[![facebook icon](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/63aaba6ee3b3be5e1e524c93_001-facebook.svg)](https://www.facebook.com/superannotate)[![x\nlogo](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/6580559a891c29b14bbdda56_X.svg)](https://x.com/superannotate)[![linkedin\nicon](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/63ad86c4da54a2e62012b3ac_linkedin-\nin.svg)](https://www.linkedin.com/company/superannotate/)\n\n[![superannotate logo](https://assets-global.website-\nfiles.com/612770618d97595db63a9470/6127731d30dc5270fa629b99_logoDark.svg)](/)\n\nCopyright \u00c2\u00a9 2024 SuperAnnotate AI, Inc. All rights reserved.\n\n![](https://px.ads.linkedin.com/collect/?pid=2683617&fmt=gif)", "start_char_idx": 31993, "end_char_idx": 34888, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e5615b6f-9d90-43e2-ad2e-3ac7999418aa": {"__data__": {"id_": "e5615b6f-9d90-43e2-ad2e-3ac7999418aa", "embedding": null, "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning", "node_type": "4", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "28b434e5790f667b01c65373aa0ef001751b67bfa1594ebf4c478fa22e0152f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "acc57967-9b3e-4843-8a89-3b6aa77acff8", "node_type": "1", "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}, "hash": "d82966b3218729c09367a44e228761171f0844305025365734647685b9a4d2e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9367eb84-c69a-408b-ac65-eddbd8d4be9f", "node_type": "1", "metadata": {}, "hash": "f78212b4d1fee0db0465001f6dd48ad4874ce1647fe2617645dea87fe282c5fb", "class_name": "RelatedNodeInfo"}}, "text": "[![Hugging Face's logo](/front/assets/huggingface_logo-noborder.svg) Hugging\nFace](/)\n\n  * [ Models](/models)\n  * [ Datasets](/datasets)\n  * [ Spaces](/spaces)\n  * [ Posts](/posts)\n  * [ Docs](/docs)\n  * Solutions \n\n  * [Pricing ](/pricing)\n  *   * * * *\n\n  * [Log In ](/login)\n  * [Sign Up ](/join)\n\nAutoTrain documentation\n\nLLM Finetuning\n\n# AutoTrain\n\n\ud83c\udfe1 View all docsAWS Trainium & InferentiaAccelerateAmazon\nSageMakerAutoTrainBitsandbytesCompetitionsDataset\nviewerDatasetsDiffusersEvaluateGoogle TPUsGradioHubHub Python\nLibraryHuggingface.jsInference API (serverless)Inference Endpoints\n(dedicated)OptimumPEFTSafetensorsSentence TransformersTRLTasksText Embeddings\nInferenceText Generation InferenceTokenizersTransformersTransformers.jstimm\n\nSearch documentation\n\nmainv0.7.69v0.6.48v0.5.2 EN\n\n[ ](https://github.com/huggingface/autotrain-advanced)\n\nGetting Started\n\n[\ud83e\udd17 AutoTrain ](/docs/autotrain/en/index)[Installation\n](/docs/autotrain/en/getting_started)[How much does it cost?\n](/docs/autotrain/en/cost)[Get help and support ](/docs/autotrain/en/support)\n\nStarting AutoTrain\n\n[Starting the UI ](/docs/autotrain/en/starting_ui)[Starting the CLI\n](/docs/autotrain/en/starting_cli)\n\nTasks\n\n[Text Classification ](/docs/autotrain/en/text_classification)[LLM Finetuning\n](/docs/autotrain/en/llm_finetuning)[Image Classification\n](/docs/autotrain/en/image_classification)[DreamBooth\n](/docs/autotrain/en/dreambooth)[Seq2Seq ](/docs/autotrain/en/seq2seq)[Token\nClassification ](/docs/autotrain/en/token_classification)[Tabular\n](/docs/autotrain/en/tabular)\n\nYou are viewing main version, which requires installation from source. If\nyou'd like regular pip install, checkout the latest stable version\n([v0.7.69](/docs/autotrain/v0.7.69/llm_finetuning)).\n\n![Hugging Face's logo](/front/assets/huggingface_logo-noborder.svg)\n\nJoin the Hugging Face community\n\nand get access to the augmented documentation experience\n\nCollaborate on models, datasets and Spaces\n\nFaster examples with accelerated inference\n\nSwitch between documentation themes\n\n[Sign Up](/join)\n\nto get started\n\n#  LLM Finetuning\n\nWith AutoTrain, you can easily finetune large language models (LLMs) on your\nown data!\n\nAutoTrain supports the following types of LLM finetuning:\n\n  * Causal Language Modeling (CLM)\n  * Masked Language Modeling (MLM) [Coming Soon]\n\n##  Data Preparation\n\nLLM finetuning accepts data in CSV format.\n\n###  Data Format For SFT / Generic Trainer\n\nFor SFT / Generic Trainer, the data should be in the following format:\n\ntext  \n---  \nhuman: hello \\n bot: hi nice to meet you  \nhuman: how are you \\n bot: I am fine  \nhuman: What is your name? \\n bot: My name is Mary  \nhuman: Which is the best programming language? \\n bot: Python  \n  \nAn example dataset for this format can be found here:\n<https://huggingface.co/datasets/timdettmers/openassistant-guanaco>\n\nFor SFT/Generic training, your dataset must have a `text` column\n\n###  Data Format For Reward Trainer\n\nFor Reward Trainer, the data should be in the following format:\n\ntext | rejected_text  \n---|---  \nhuman: hello \\n bot: hi nice to meet you | human: hello \\n bot: leave me alone  \nhuman: how are you \\n bot: I am fine | human: how are you \\n bot: I am not\nfine  \nhuman: What is your name? \\n bot: My name is Mary | human: What is your name?\n\\n bot: Whats it to you?  \nhuman: Which is the best programming language? \\n bot: Python | human: Which\nis the best programming language? \\n bot: Javascript  \n  \nFor Reward Trainer, your dataset must have a `text` column (aka chosen text)\nand a `rejected_text` column.", "start_char_idx": 0, "end_char_idx": 3553, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9367eb84-c69a-408b-ac65-eddbd8d4be9f": {"__data__": {"id_": "9367eb84-c69a-408b-ac65-eddbd8d4be9f", "embedding": null, "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning", "node_type": "4", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "28b434e5790f667b01c65373aa0ef001751b67bfa1594ebf4c478fa22e0152f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e5615b6f-9d90-43e2-ad2e-3ac7999418aa", "node_type": "1", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "91fa209aabfae81d16e2c5019587e68bf34b1efc814c63d3df364a2bede8443f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c73b40ca-c266-4888-a2fb-742ae2fcb791", "node_type": "1", "metadata": {}, "hash": "965281046e36d32eff63b79f35d92277d644cc644efda088108c8a2f87e49957", "class_name": "RelatedNodeInfo"}}, "text": "\\n bot: My name is Mary | human: What is your name?\n\\n bot: Whats it to you?  \nhuman: Which is the best programming language? \\n bot: Python | human: Which\nis the best programming language? \\n bot: Javascript  \n  \nFor Reward Trainer, your dataset must have a `text` column (aka chosen text)\nand a `rejected_text` column.\n\n###  Data Format For DPO Trainer\n\nFor DPO Trainer, the data should be in the following format:\n\nprompt | text | rejected_text  \n---|---|---  \nhello | hi nice to meet you | leave me alone  \nhow are you | I am fine | I am not fine  \nWhat is your name? | My name is Mary | Whats it to you?  \nWhat is your name? | My name is Mary | I dont have a name  \nWhich is the best programming language? | Python | Javascript  \nWhich is the best programming language? | Python | C++  \nWhich is the best programming language? | Java | C++  \n  \nFor DPO Trainer, your dataset must have a `prompt` column, a `text` column\n(aka chosen text) and a `rejected_text` column.\n\nFor all tasks, you can use both CSV and JSONL files!\n\n##  Parameters\n\nCopied\n\n    \n    \n    \u276f autotrain llm --help\n    usage: autotrain <command> [<args>] llm [-h] [--train] [--deploy] [--inference] [--username USERNAME]\n                                            [--backend {local-cli,spaces-a10gl,spaces-a10gs,spaces-a100,spaces-t4m,spaces-t4s,spaces-cpu,spaces-cpuf}]\n                                            [--token TOKEN] [--push-to-hub] --model MODEL --project-name PROJECT_NAME [--data-path DATA_PATH]\n                                            [--train-split TRAIN_SPLIT] [--valid-split VALID_SPLIT] [--batch-size BATCH_SIZE] [--seed SEED]\n                                            [--epochs EPOCHS] [--gradient_accumulation GRADIENT_ACCUMULATION] [--disable_gradient_checkpointing]\n                                            [--lr LR] [--log {none,wandb,tensorboard}] [--text_column TEXT_COLUMN]\n                                            [--rejected_text_column REJECTED_TEXT_COLUMN] [--prompt-text-column PROMPT_TEXT_COLUMN]\n                                            [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO] [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n                                            [--weight_decay WEIGHT_DECAY] [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token] [--block_size BLOCK_SIZE]\n                                            [--peft] [--lora_r LORA_R] [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n                                            [--logging_steps LOGGING_STEPS] [--evaluation_strategy {epoch,steps,no}]\n                                            [--save_total_limit SAVE_TOTAL_LIMIT] [--auto_find_batch_size]\n                                            [--mixed_precision {fp16,bf16,None}] [--quantization {int4,int8,None}] [--model_max_length MODEL_MAX_LENGTH]\n                                            [--max_prompt_length MAX_PROMPT_LENGTH] [--max_completion_length MAX_COMPLETION_LENGTH]\n                                            [--trainer {default,dpo,sft,orpo,reward}] [--target_modules TARGET_MODULES] [--merge_adapter]\n                                            [--use_flash_attention_2] [--dpo-beta DPO_BETA] [--chat_template {tokenizer,chatml,zephyr,None}]\n                                            [--padding {left,right,None}]\n    \n    \u2728 Run AutoTrain LLM\n    \n    options:\n      -h, --help            show this help message and exit\n      --train               Command to train the model\n      --deploy              Command to deploy the model (limited availability)\n      --inference           Command to run inference (limited availability)\n      --username USERNAME   Hugging Face Hub Username\n      --backend {local-cli,spaces-a10gl,spaces-a10gs,spaces-a100,spaces-t4m,spaces-t4s,spaces-cpu,spaces-cpuf}\n                            Backend to use: default or spaces. Spaces backend requires push_to_hub & username. Advanced users only.\n      --token TOKEN         Your Hugging Face API token. Token must have write access to the model hub.\n      --push-to-hub         Push to hub after training will push the trained model to the Hugging Face model hub.\n      --model MODEL         Base model to use for training\n      --project-name PROJECT_NAME\n                            Output directory / repo id for trained model (must be unique on hub)\n      --data-path DATA_PATH\n                            Train dataset to use.", "start_char_idx": 3233, "end_char_idx": 7637, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c73b40ca-c266-4888-a2fb-742ae2fcb791": {"__data__": {"id_": "c73b40ca-c266-4888-a2fb-742ae2fcb791", "embedding": null, "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning", "node_type": "4", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "28b434e5790f667b01c65373aa0ef001751b67bfa1594ebf4c478fa22e0152f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9367eb84-c69a-408b-ac65-eddbd8d4be9f", "node_type": "1", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "bfc69a42800ddda69cefb14b4be2350403998582f2fec2f0ee8dfade6c024f34", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1baf43b1-3ef9-445c-a405-8b9ad040700b", "node_type": "1", "metadata": {}, "hash": "59d4e5563ad8267daf93dec94656745b1a4705ca2751813fd5c70c8032201856", "class_name": "RelatedNodeInfo"}}, "text": "Spaces backend requires push_to_hub & username. Advanced users only.\n      --token TOKEN         Your Hugging Face API token. Token must have write access to the model hub.\n      --push-to-hub         Push to hub after training will push the trained model to the Hugging Face model hub.\n      --model MODEL         Base model to use for training\n      --project-name PROJECT_NAME\n                            Output directory / repo id for trained model (must be unique on hub)\n      --data-path DATA_PATH\n                            Train dataset to use. When using cli, this should be a directory path containing training and validation data in appropriate\n                            formats\n      --train-split TRAIN_SPLIT\n                            Train dataset split to use\n      --valid-split VALID_SPLIT\n                            Validation dataset split to use\n      --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n                            Training batch size to use\n      --seed SEED           Random seed for reproducibility\n      --epochs EPOCHS       Number of training epochs\n      --gradient_accumulation GRADIENT_ACCUMULATION, --gradient-accumulation GRADIENT_ACCUMULATION\n                            Gradient accumulation steps\n      --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n                            Disable gradient checkpointing\n      --lr LR               Learning rate\n      --log {none,wandb,tensorboard}\n                            Use experiment tracking\n      --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n                            Specify the dataset column to use for text data. This parameter is essential for models processing textual information.\n                            Default is 'text'.\n      --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n                            Define the column to use for storing rejected text entries, which are typically entries that do not meet certain criteria\n                            for processing. Default is 'rejected'. Used only for orpo, dpo and reward trainerss\n      --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n                            Identify the column that contains prompt text for tasks requiring contextual inputs, such as conversation or completion\n                            generation. Default is 'prompt'. Used only for dpo trainer\n      --model-ref MODEL_REF\n                            Reference model to use for DPO when not using PEFT\n      --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n                            Set the proportion of training allocated to warming up the learning rate, which can enhance model stability and performance\n                            at the start of training. Default is 0.1\n      --optimizer OPTIMIZER\n                            Choose the optimizer algorithm for training the model. Different optimizers can affect the training speed and model\n                            performance. 'adamw_torch' is used by default.\n      --scheduler SCHEDULER\n                            Select the learning rate scheduler to adjust the learning rate based on the number of epochs. 'linear' decreases the\n                            learning rate linearly from the initial lr set. Default is 'linear'. Try 'cosine' for a cosine annealing schedule.\n      --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n                            Define the weight decay rate for regularization, which helps prevent overfitting by penalizing larger weights. Default is\n                            0.0\n      --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n                            Set the maximum norm for gradient clipping, which is critical for preventing gradients from exploding during\n                            backpropagation. Default is 1.0.\n      --add_eos_token, --add-eos-token\n                            Toggle whether to automatically add an End Of Sentence (EOS) token at the end of texts, which can be critical for certain\n                            types of models like language models. Only used for `default` trainer\n      --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n                            Specify the block size for processing sequences. This is maximum sequence length or length of one block of text. Setting to\n                            -1 determines block size automatically. Default is -1.\n      --peft, --use-peft    Enable LoRA-PEFT\n      --lora_r LORA_R, --lora-r LORA_R\n                            Set the 'r' parameter for Low-Rank Adaptation (LoRA). Default is 16.\n      --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n                            Specify the 'alpha' parameter for LoRA. Default is 32.\n      --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n                            Set the dropout rate within the LoRA layers to help prevent overfitting during adaptation. Default is 0.05.", "start_char_idx": 7083, "end_char_idx": 12109, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1baf43b1-3ef9-445c-a405-8b9ad040700b": {"__data__": {"id_": "1baf43b1-3ef9-445c-a405-8b9ad040700b", "embedding": null, "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning", "node_type": "4", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "28b434e5790f667b01c65373aa0ef001751b67bfa1594ebf4c478fa22e0152f5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c73b40ca-c266-4888-a2fb-742ae2fcb791", "node_type": "1", "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}, "hash": "b100d8662f6cd3e17037733504b76d4e0d130e098f4252b10615659d77d9f46b", "class_name": "RelatedNodeInfo"}}, "text": "This is maximum sequence length or length of one block of text. Setting to\n                            -1 determines block size automatically. Default is -1.\n      --peft, --use-peft    Enable LoRA-PEFT\n      --lora_r LORA_R, --lora-r LORA_R\n                            Set the 'r' parameter for Low-Rank Adaptation (LoRA). Default is 16.\n      --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n                            Specify the 'alpha' parameter for LoRA. Default is 32.\n      --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n                            Set the dropout rate within the LoRA layers to help prevent overfitting during adaptation. Default is 0.05.\n      --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n                            Determine how often to log training progress in terms of steps. Setting it to '-1' determines logging steps automatically.\n      --evaluation_strategy {epoch,steps,no}, --evaluation-strategy {epoch,steps,no}\n                            Choose how frequently to evaluate the model's performance, with 'epoch' as the default, meaning at the end of each training\n                            epoch\n      --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n                            Limit the total number of saved model checkpoints to manage disk usage effectively. Default is to save only the latest\n                            checkpoint\n      --auto_find_batch_size, --auto-find-batch-size\n                            Automatically determine the optimal batch size based on system capabilities to maximize efficiency.\n      --mixed_precision {fp16,bf16,None}, --mixed-precision {fp16,bf16,None}\n                            Choose the precision mode for training to optimize performance and memory usage. Options are 'fp16', 'bf16', or None for\n                            default precision. Default is None.\n      --quantization {int4,int8,None}, --quantization {int4,int8,None}\n                            Choose the quantization level to reduce model size and potentially increase inference speed. Options include 'int4', 'int8',\n                            or None. Enabling requires --peft\n      --model_max_length MODEL_MAX_LENGTH, --model-max-length MODEL_MAX_LENGTH\n                            Set the maximum length for the model to process in a single batch, which can affect both performance and memory usage.\n                            Default is 1024\n      --max_prompt_length MAX_PROMPT_LENGTH, --max-prompt-length MAX_PROMPT_LENGTH\n                            Specify the maximum length for prompts used in training, particularly relevant for tasks requiring initial contextual input.\n                            Used only for `orpo` trainer.\n      --max_completion_length MAX_COMPLETION_LENGTH, --max-completion-length MAX_COMPLETION_LENGTH\n                            Completion length to use, for orpo: encoder-decoder models only\n      --trainer {default,dpo,sft,orpo,reward}\n                            Trainer type to use\n      --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n                            Identify specific modules within the model architecture to target with adaptations or optimizations, such as LoRA. Comma\n                            separated list of module names. Default is 'all-linear'.\n      --merge_adapter, --merge-adapter\n                            Use this flag to merge PEFT adapter with the model\n      --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n                            Use flash attention 2\n      --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n                            Beta for DPO trainer\n      --chat_template {tokenizer,chatml,zephyr,None}, --chat-template {tokenizer,chatml,zephyr,None}\n                            Apply a specific template for chat-based interactions, with options including 'tokenizer', 'chatml', 'zephyr', or None. This\n                            setting can shape the model's conversational behavior.\n      --padding {left,right,None}, --padding {left,right,None}\n                            Specify the padding direction for sequences, critical for models sensitive to input alignment. Options include 'left',\n                            'right', or None\n\n[< > Update on GitHub](https://github.com/huggingface/autotrain-\nadvanced/blob/main/docs/source/llm_finetuning.mdx)\n\n[\u2190Text Classification](/docs/autotrain/en/text_classification) [Image\nClassification\u2192](/docs/autotrain/en/image_classification)\n\nLLM Finetuning Data Preparation Data Format For SFT / Generic Trainer Data\nFormat For Reward Trainer Data Format For DPO Trainer Parameters", "start_char_idx": 11434, "end_char_idx": 16083, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"https://www.superannotate.com/blog/llm-fine-tuning": {"node_ids": ["dbcc8a39-c151-4294-8bbd-1250c20cd68b", "54a2be4f-7ea2-4007-aee7-a4740bccbf5f", "4ee12d5a-0677-48d0-8e24-6e1bc8983123", "12aa42a6-916b-403e-8ede-a9fd74920948", "fba7d9d1-33e2-4c1d-8059-8bb627998ed7", "a13b8a84-de91-480d-84ba-bbd6cd9d1c46", "6caa0c66-12bc-408d-808a-1b12e97af0c9", "9bc76aa2-e6ba-4919-ab73-7faa2108603d", "cb2ff625-795d-4822-a50c-17d3716352ec", "0a812a0a-4717-4fad-bd5c-d10b3b5e61bd", "acc57967-9b3e-4843-8a89-3b6aa77acff8"], "metadata": {"doc_id": "https://www.superannotate.com/blog/llm-fine-tuning"}}, "https://huggingface.co/docs/autotrain/en/llm_finetuning": {"node_ids": ["e5615b6f-9d90-43e2-ad2e-3ac7999418aa", "9367eb84-c69a-408b-ac65-eddbd8d4be9f", "c73b40ca-c266-4888-a2fb-742ae2fcb791", "1baf43b1-3ef9-445c-a405-8b9ad040700b"], "metadata": {"doc_id": "https://huggingface.co/docs/autotrain/en/llm_finetuning"}}}}